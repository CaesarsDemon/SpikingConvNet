%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional
  \DeclareUnicodeCharacter{"00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{"2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{"2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{"2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{"251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{"2572}{\textbackslash}
 \else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{2572}{\textbackslash}
 \fi
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage[dontkeepoldnames]{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}



\title{Toolbox for Building Deep Spiking ConvNets - Documentation}
\date{Feb 28, 2018}
\release{1.0}
\author{Sven Gronauer}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}



\chapter{Introduction}
\label{\detokenize{introduction:introduction}}\label{\detokenize{introduction::doc}}\label{\detokenize{introduction:welcome-to-the-documentation}}
That has a paragraph about a main subject and is set when the ‘=’
is at least the same length of the title itself.


\section{Subtitle}
\label{\detokenize{introduction:subtitle}}
\sphinxstyleemphasis{Subtitles} are set with ‘-‘ and are required to have the same length
of the subtitle itself, just like titles.

Lists can be unnumbered like:
\begin{itemize}
\item {} 
Item Foo

\item {} 
Item Bar

\end{itemize}

Or automatically numbered:
\begin{enumerate}
\item {} 
Item 1

\item {} 
Item 2

\end{enumerate}


\section{Subtitle}
\label{\detokenize{introduction:id1}}
Words can have \sphinxstyleemphasis{emphasis in italics} ors be \sphinxstylestrong{bold} and you can define
code samples with back quotes, like when you talk about a command: \sphinxcode{sudo}
gives you super user powers!

Build the documentation:
\begin{enumerate}
\item {} 
change directory \sphinxcode{cd docs/}

\item {} 
render \sphinxcode{/programming/test\_sphynx/docs\$ sphinx-apidoc -f -o source/ ../SpikingConvNet/}

\item {} 
excute \sphinxcode{make html}

\end{enumerate}


\chapter{Sample Code}
\label{\detokenize{samplecode::doc}}\label{\detokenize{samplecode:sample-code}}
This section describes how to setup a simple Deep Spiking Convolutional Neural Network (DSCNN).


\section{Simple 1-Layer ConvNet}
\label{\detokenize{samplecode:simple-1-layer-convnet}}
Let’s start with training a simple SCNN with one convolutional Layer. By creating firstly the model structure with the following python code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{SpikingModel}\PYG{p}{(}\PYG{n}{input\PYGZus{}tensor}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{run\PYGZus{}control}\PYG{o}{=}\PYG{n}{rc}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{ConvLayer}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{stride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Classifier}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

In order to build the network structure on SpiNNaker Hardware, you have to execute commands in the terminal:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode loaddata
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer \PYG{l+m}{1}
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer svm
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode testing
\end{sphinxVerbatim}


\section{Deeper ConvNet}
\label{\detokenize{samplecode:deeper-convnet}}
Theoritically, as many layers as appreciated can be build. Therefore convolutional layers are added to the model are added in sequential manner.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{SpikingModel}\PYG{p}{(}\PYG{n}{input\PYGZus{}tensor}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{run\PYGZus{}control}\PYG{o}{=}\PYG{n}{rc}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{ConvLayer}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{stride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{ConvLayer}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{stride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{ConvLayer}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,} \PYG{n}{stride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Classifier}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode loaddata
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer \PYG{l+m}{1}
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer \PYG{l+m}{2}
\PYG{g+go}{...}
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer n
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer svm
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode testing
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
The training of the Network is done layer by layer, hence the input spikes of the currently trained layer depend on the previous layer.
So a new simulation cycle is started the previously calculated layers are flattend to achieve parallel computation.
\end{sphinxadmonition}


\chapter{SpikingConvNet}
\label{\detokenize{modules:spikingconvnet}}\label{\detokenize{modules::doc}}

\section{SpikingConvNet package}
\label{\detokenize{SpikingConvNet:spikingconvnet-package}}\label{\detokenize{SpikingConvNet::doc}}

\subsection{Submodules}
\label{\detokenize{SpikingConvNet:submodules}}

\subsection{SpikingConvNet.algorithms module}
\label{\detokenize{SpikingConvNet:module-SpikingConvNet.algorithms}}\label{\detokenize{SpikingConvNet:spikingconvnet-algorithms-module}}\index{SpikingConvNet.algorithms (module)}
Deep Spiking Convolutional Neural Network
with STDP Learning Rule on MNIST data
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Research Internship
Technical University Munich
Creator:    Sven Gronauer
Date:       February 2018
\index{input\_flattend\_spikes() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.input_flattend_spikes}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{input\_flattend\_spikes}}{\emph{X\_train}, \emph{tensor\_input}, \emph{kernel\_shape}}{}
Create flattend SpikeSourceArray for input neurons
instance: rebuilding network

For rebuilding the network structure the input neurons are not windowed
over time, instead the input layer is flattend and a whole image is
presented to the network in each simulation interval
The corresponding spiketimes depend on pixel intensities and are
stochastically rate-coded.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X\_train} (\sphinxstyleemphasis{np.array, shape = {[}n\_examples, image\_intensities.flatten(){]}}) \textendash{} dataset of MNIST input images as 2d-array

\item {} 
\sphinxstylestrong{tensor\_input} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of input layer

\item {} 
\sphinxstylestrong{kernel\_shape} (\sphinxstyleemphasis{tuple of int}) \textendash{} Kernel shape

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{spiketrains} \textendash{} Each datapoint contains precise spike times for each input neuron

\item[{Return type}] \leavevmode
np.array, shape = {[}n\_examples, spike\_times{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{input\_windowed\_spikes() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.input_windowed_spikes}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{input\_windowed\_spikes}}{\emph{X\_train}, \emph{tensor\_input}, \emph{kernel\_shape}, \emph{stride}}{}
Create windowed SpikeSourceArray for input neurons
instance: training layer in network

Input patterns are windowed over time, post-neurons are presented only
a subset of the input pattern. The corresponding spiketimes depend on
pixel intensities and are stochastically rate-coded.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{X\_train} (\sphinxstyleemphasis{np.array, shape = {[}n\_examples, image\_intensities.flatten(){]}})

\item[{Returns}] \leavevmode
\sphinxstylestrong{spiketrains} \textendash{} Each datapoint contains precise spike times for each input neuron

\item[{Return type}] \leavevmode
np.array, shape = {[}n\_examples*n\_windows, spike\_times{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{rebuild\_fixed\_connections() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.rebuild_fixed_connections}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{rebuild\_fixed\_connections}}{\emph{tensor\_first}, \emph{tensor\_second}, \emph{kernel\_shape}, \emph{stride}, \emph{weights\_tensor}}{}
Construct connections between flattend layers
use learned STDP weights and fix them
now computation in parallel
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{tensor\_first} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of previous layer

\item {} 
\sphinxstylestrong{tensor\_second} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of posterior layer

\item {} 
\sphinxstylestrong{kernel\_shape} (\sphinxstyleemphasis{tuple of int}) \textendash{} Kernel shape

\item {} 
\sphinxstylestrong{stride} (\sphinxstyleemphasis{int}) \textendash{} Specified stride over convolved layer

\item {} 
\sphinxstylestrong{weights\_tensor} (\sphinxstyleemphasis{np.array, shape={[}n\_kernel, kernel\_height*kernel\_width{]}}) \textendash{} Previously trained STDP weights, now initialized as fixed weights

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{connection\_list} \textendash{} list for s.FromListConnector()

\item[{Return type}] \leavevmode
list of {[}position\_1, position\_2, weight , delay{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{rebuild\_inhibitory\_connections() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.rebuild_inhibitory_connections}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{rebuild\_inhibitory\_connections}}{\emph{tensor\_prev}, \emph{tensor\_layer}, \emph{inhib\_weight}}{}
construct inhibitory connections within flattend layers

-\textgreater{} not used in final implementation !
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{tensor\_prev} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of previous layer

\item {} 
\sphinxstylestrong{tensor\_layer} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of actual layer

\item {} 
\sphinxstylestrong{inhib\_weight} (\sphinxstyleemphasis{float32}) \textendash{} fixed weight for inhibitory connection

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{inhib\_connection\_list} \textendash{} list for s.FromListConnector()

\item[{Return type}] \leavevmode
list of {[}position\_1, position\_2, weight , delay{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{spikes\_for\_classifier() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.spikes_for_classifier}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{spikes\_for\_classifier}}{\emph{rc}, \emph{tensor}, \emph{spiketrains}}{}
Transform spiketrains to plain two-dimensional dataset

to reduce the power of Support Vector Machine, the quantity of spikes
within each simulation interval are counted for each neuron in the last
layer
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{tensor} (\sphinxstyleemphasis{tuple of int}) \textendash{} Tensor of last Convolutional layer in network

\item {} 
\sphinxstylestrong{spiketrains} (\sphinxstyleemphasis{SpikeTrain object}) \textendash{} Retrieved spikes from last layer on SpiNNaker board
SpikeTrains objects are extracted from Neo Block Segments

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{X} \textendash{} Each datapoint contains number of spikes for each post-neuron
within one sim interval

\item[{Return type}] \leavevmode
np.array, shape = {[}datapoints, n\_neurons\_last\_layer{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{windowed\_spikes() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.windowed_spikes}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{windowed\_spikes}}{\emph{spiketrains\_input}, \emph{tensor\_first}, \emph{tensor\_second}, \emph{kernel\_shape}, \emph{stride}}{}
Create windowed SpikeSourceArray
instance: training deeper layer in network

Input spiketrains are windowed over time, post-neurons are presented only
a subset of the input spiketrains. The corresponding output spiketimes
depend on calculated spikes (spiketrains\_input) of previous layer.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{spiketrains\_input} (\sphinxstyleemphasis{SpikeTrain object}) \textendash{} Spiketrains from previous layer

\item {} 
\sphinxstylestrong{tensor\_first} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of previous layer

\item {} 
\sphinxstylestrong{tensor\_second} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of posterior layer

\item {} 
\sphinxstylestrong{kernel\_shape} (\sphinxstyleemphasis{tuple of int}) \textendash{} Kernel shape

\item {} 
\sphinxstylestrong{stride} (\sphinxstyleemphasis{int}) \textendash{} Specified stride over convolved layer

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{spiketrains} \textendash{} Each datapoint contains precise spike times for each neuron

\item[{Return type}] \leavevmode
np.array, shape = {[}n\_examples*windows, spike\_times{]}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{SpikingConvNet.classes module}
\label{\detokenize{SpikingConvNet:module-SpikingConvNet.classes}}\label{\detokenize{SpikingConvNet:spikingconvnet-classes-module}}\index{SpikingConvNet.classes (module)}
Deep Spiking Convolutional Neural Network
with STDP Learning Rule on MNIST data
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Research Internship
Technical University Munich
Creator:    Sven Gronauer
Date:       February 2018
\index{Classifier (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Classifier}}\pysigline{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{Classifier}}
Bases: {\hyperref[\detokenize{SpikingConvNet:SpikingConvNet.classes.Layer}]{\sphinxcrossref{\sphinxcode{SpikingConvNet.classes.Layer}}}}
\index{classify() (SpikingConvNet.classes.Classifier method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Classifier.classify}}\pysiglinewithargsret{\sphinxbfcode{classify}}{\emph{X\_test}, \emph{y\_test}}{}
determine classification accuracy of SVC with given Testset

\end{fulllineitems}

\index{train() (SpikingConvNet.classes.Classifier method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Classifier.train}}\pysiglinewithargsret{\sphinxbfcode{train}}{\emph{X\_train}, \emph{y\_train}}{}
train parameters with given Trainset

\end{fulllineitems}


\end{fulllineitems}

\index{ConvLayer (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.ConvLayer}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{ConvLayer}}{\emph{kernels}, \emph{shape}, \emph{stride}}{}
Bases: {\hyperref[\detokenize{SpikingConvNet:SpikingConvNet.classes.Layer}]{\sphinxcrossref{\sphinxcode{SpikingConvNet.classes.Layer}}}}

\end{fulllineitems}

\index{InputLayer (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.InputLayer}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{InputLayer}}{\emph{tensor}}{}
Bases: {\hyperref[\detokenize{SpikingConvNet:SpikingConvNet.classes.Layer}]{\sphinxcrossref{\sphinxcode{SpikingConvNet.classes.Layer}}}}

\end{fulllineitems}

\index{Layer (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Layer}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{Layer}}{\emph{rc}}{}
Bases: \sphinxcode{object}

\end{fulllineitems}

\index{SpikingModel (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.SpikingModel}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{SpikingModel}}{\emph{input\_tensor}, \emph{run\_control}}{}
Bases: \sphinxcode{object}
\index{add() (SpikingConvNet.classes.SpikingModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.SpikingModel.add}}\pysiglinewithargsret{\sphinxbfcode{add}}{\emph{layer}}{}
\end{fulllineitems}

\index{calculate\_tensors() (SpikingConvNet.classes.SpikingModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.SpikingModel.calculate_tensors}}\pysiglinewithargsret{\sphinxbfcode{calculate\_tensors}}{}{}
\end{fulllineitems}

\index{print\_structure() (SpikingConvNet.classes.SpikingModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.SpikingModel.print_structure}}\pysiglinewithargsret{\sphinxbfcode{print\_structure}}{}{}
\end{fulllineitems}


\end{fulllineitems}

\index{Spinnaker\_Network (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Spinnaker_Network}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{Spinnaker\_Network}}{\emph{runcontrol}, \emph{model}, \emph{deepspikes=None}}{}
Class for implementing neural network on SpiNNaker

The following steps are processed through calling the class constructor
(almost the same as PyNN basic setup structure)
\#. Initialize with constructor
\#. load datasets (Train and Testset) from files
\#. Load previously calculated weights for layers
\#. Create populations
\#. Build STDP-model
\#. Build projections between populations
\#. Setup recordings

These methods must be called from external fuction(s):
* update\_kernel\_weights() - Determine current weights in STDP trained layer
* retrieve\_data() - Receive observed data from SpiNNaker
* print\_parameters() - Display Information of Neural Network
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{runcotrol} (\sphinxstyleemphasis{RunControl object}) \textendash{} Structure that contains basic information for program flow such as
passed args from terminal command, backup commands, building options
for SpiNNaker network

\item {} 
\sphinxstylestrong{model} (\sphinxstyleemphasis{SpikingModel object}) \textendash{} predefined model of spiking neural network

\item {} 
\sphinxstylestrong{deepspikes} (\sphinxstyleemphasis{Spiketrain object}) \textendash{} training a deeper layer requires preprocessed spikes from previous
layer, hence training of Spiking Neural Network is done layer by
layer

\end{itemize}

\end{description}\end{quote}
\index{print\_parameters() (SpikingConvNet.classes.Spinnaker\_Network method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Spinnaker_Network.print_parameters}}\pysiglinewithargsret{\sphinxbfcode{print\_parameters}}{}{}
\end{fulllineitems}

\index{retrieve\_data() (SpikingConvNet.classes.Spinnaker\_Network method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Spinnaker_Network.retrieve_data}}\pysiglinewithargsret{\sphinxbfcode{retrieve\_data}}{}{}
Transmit observed data of spikes and voltages from SpiNNaker Board
to host computer
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{spiketrains} (\sphinxstyleemphasis{SpikeTrain object}) \textendash{} Spiketrains from last layer in neural network

\item {} 
\sphinxstylestrong{list} (\sphinxstyleemphasis{{[}spikes\_in, spikes\_1, v\_1{]}}) \textendash{} {\color{red}\bfseries{}*}spikes\_in: spiketimes input layer
{\color{red}\bfseries{}*}spikes\_1: spikes post-neurons
{\color{red}\bfseries{}*}v\_1: membrane potentials of post-neurons

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{update\_kernel\_weights() (SpikingConvNet.classes.Spinnaker\_Network method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Spinnaker_Network.update_kernel_weights}}\pysiglinewithargsret{\sphinxbfcode{update\_kernel\_weights}}{}{}
Update the internal stored weights of trained layer with STDP Rule

returns current STDP weight values of trained Layer

\end{fulllineitems}


\end{fulllineitems}



\subsection{SpikingConvNet.parameters module}
\label{\detokenize{SpikingConvNet:spikingconvnet-parameters-module}}\label{\detokenize{SpikingConvNet:module-SpikingConvNet.parameters}}\index{SpikingConvNet.parameters (module)}
Deep Spiking Convolutional Neural Network
with STDP Learning Rule on MNIST data
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Research Internship
Technical University Munich
Creator:    Sven Gronauer
Date:       February 2018


\subsection{SpikingConvNet.utils module}
\label{\detokenize{SpikingConvNet:spikingconvnet-utils-module}}\label{\detokenize{SpikingConvNet:module-SpikingConvNet.utils}}\index{SpikingConvNet.utils (module)}
Utilities for controling program flow, data handling and data plotting
\index{RunControl (class in SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.RunControl}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{RunControl}}{\emph{args}, \emph{trainlayer=0}, \emph{trainsvm=False}, \emph{rebuild=False}}{}
Bases: \sphinxcode{object}

Object for controlling program flow, contains args from console and sets
up the logging utility
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{args} (\sphinxstyleemphasis{ArgumentParser object}) \textendash{} Passed arguments from terminal command

\item {} 
\sphinxstylestrong{trainlayer} (\sphinxstyleemphasis{int, optional}) \textendash{} If not zero, specifies which layer of network to train

\item {} 
\sphinxstylestrong{trainsvm} (\sphinxstyleemphasis{bool, optional}) \textendash{} If given, classifier is trained

\item {} 
\sphinxstylestrong{rebuild} (\sphinxstyleemphasis{bool, optional}) \textendash{} Controls the behaviour of the follow up build of neural network
(as a variable of programs state machine)
\begin{itemize}
\item {} 
\sphinxcode{rebuild==True} in order to train layer n, the spikes of layer n-1 must be determined

\item {} 
\sphinxcode{rebuild==False} a layer or the Classifier is trained

\end{itemize}

\end{itemize}

\end{description}\end{quote}
\index{setup\_logger() (SpikingConvNet.utils.RunControl method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.RunControl.setup_logger}}\pysiglinewithargsret{\sphinxbfcode{setup\_logger}}{}{}
Setup logger for tracking infos and errors

\end{fulllineitems}


\end{fulllineitems}

\index{convert\_rate\_code() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.convert_rate_code}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{convert\_rate\_code}}{\emph{intensity}, \emph{total\_intensity=None}}{}
Rate Coding of input pixel

calculate spike times depended on pixel intensity of pre-neuron
\begin{description}
\item[{Args:}] \leavevmode
intensity: pixel intensity {[}0, 255{]}
total\_intensity: Sum of intensities of input pattern,
\begin{quote}

used for normalization
\end{quote}

\end{description}

\end{fulllineitems}

\index{convert\_time\_code() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.convert_time_code}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{convert\_time\_code}}{\emph{intensity}}{}
assign pixel intensity to time intervall

\end{fulllineitems}

\index{dog\_filter() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.dog_filter}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{dog\_filter}}{\emph{image}}{}
Apply Difference of Gaussian Filter to image
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{image} (\sphinxstyleemphasis{np.array, shape={[}height, width{]}}) \textendash{} Image to be transformed

\item[{Returns}] \leavevmode
\sphinxstylestrong{norm\_dog} \textendash{} Transformed image

\item[{Return type}] \leavevmode
np.array, shape={[}height, width{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_MNIST\_digits\_ordered() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.load_MNIST_digits_ordered}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{load\_MNIST\_digits\_ordered}}{\emph{args}}{}
Load MNIST dataset in chronological order

\end{fulllineitems}

\index{load\_MNIST\_digits\_shuffled() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.load_MNIST_digits_shuffled}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{load\_MNIST\_digits\_shuffled}}{\emph{rc}, \emph{mode}}{}
Load MNIST dataset

load defined number of examples (see parameters.py)
loaded subset of digits is defined in SUBSET\_DIGITS

shuffle data and return as 2d-arrays

\end{fulllineitems}

\index{plot\_confusion\_matrix() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_confusion_matrix}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_confusion\_matrix}}{\emph{rc}, \emph{cm}, \emph{normalize=True}, \emph{title='Confusion\_matrix'}, \emph{cmap=\textless{}matplotlib.colors.LinearSegmentedColormap object\textgreater{}}}{}
This function prints and plots the confusion matrix.
Normalization can be applied by setting \sphinxtitleref{normalize=True}.

\end{fulllineitems}

\index{plot\_heatpmap() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_heatpmap}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_heatpmap}}{\emph{rc}, \emph{list\_of\_elements}, \emph{title='Default Title'}, \emph{delta=False}}{}
plot matrix of heatmaps
\begin{quote}\begin{description}
\item[{Delta}] \leavevmode
if True - plot differential images

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_membran\_voltages() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_membran_voltages}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_membran\_voltages}}{\emph{rc}, \emph{v\_data}, \emph{simtime}, \emph{title='Membrane potentials'}, \emph{path=None}}{}
\end{fulllineitems}

\index{plot\_spike\_activity() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_spike_activity}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_spike\_activity}}{\emph{rc}, \emph{spiketrains}, \emph{tensor}, \emph{title='plot\_spike\_activity'}}{}
\end{fulllineitems}

\index{plot\_spikes() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_spikes}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_spikes}}{\emph{rc}, \emph{pre}, \emph{post=None}, \emph{title='Spikes Plot'}, \emph{path=None}}{}
Plot spikes of given layers
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{rc} (\sphinxstyleemphasis{RunControl object}) \textendash{} contains information of backup behaviour

\item {} 
\sphinxstylestrong{pre} (\sphinxstyleemphasis{SpikeTrain object}) \textendash{} Spiketrains of first layer to plot

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{norm\_dog} \textendash{} Transformed image

\item[{Return type}] \leavevmode
np.array, shape={[}height, width{]}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{Module contents}
\label{\detokenize{SpikingConvNet:module-SpikingConvNet}}\label{\detokenize{SpikingConvNet:module-contents}}\index{SpikingConvNet (module)}
Package for building Spiking Deep Convolutional Neural Networks on SpiNNaker
\begin{itemize}
\item {} 
Neuroscientific System Theory

\item {} 
Technical University Munich

\item {} 
Creator:    Sven Gronauer

\item {} 
Date:       February 2018

\end{itemize}

The modules inside of this package are packed with useful features
for the programmer who needs to build convolutional networks on SpiNNaker:

\sphinxcode{classes}
\begin{quote}

This module provides classes for creating objects of the neural network
model and the necessary infracture for building networks on SpiNNaker
\end{quote}

\sphinxcode{algorithms}
\begin{quote}

Here, algorithms are provided for generating sparse connections between
populations with the support of convolutions and kernels.
\end{quote}

\sphinxcode{utils}
\begin{quote}

Supporting functions to plot data, manipulate images, load MNIST dataset
and convert spike coding scheme.
\end{quote}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{s}
\item {\sphinxstyleindexentry{SpikingConvNet}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet}}
\item {\sphinxstyleindexentry{SpikingConvNet.algorithms}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet.algorithms}}
\item {\sphinxstyleindexentry{SpikingConvNet.classes}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet.classes}}
\item {\sphinxstyleindexentry{SpikingConvNet.parameters}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet.parameters}}
\item {\sphinxstyleindexentry{SpikingConvNet.utils}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet.utils}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}