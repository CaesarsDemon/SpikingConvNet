%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional
  \DeclareUnicodeCharacter{"00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{"2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{"2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{"2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{"251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{"2572}{\textbackslash}
 \else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{2572}{\textbackslash}
 \fi
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage[dontkeepoldnames]{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}



\title{Python Package for Building Deep Spiking Convolutional Neural Networks on SpiNNaker - Documentation}
\date{Mar 08, 2018}
\release{1.0}
\author{Sven Gronauer}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}



\chapter{Introduction}
\label{\detokenize{introduction:introduction}}\label{\detokenize{introduction::doc}}\label{\detokenize{introduction:welcome-to-the-documentation}}
This Python Package offers a convenient way of defining a Spiking Convolutional Neural Network on SpiNNaker Hardware.
The network, however, is trained in unsupervised manner layer by layer.


\section{Requirements}
\label{\detokenize{introduction:requirements}}\begin{itemize}
\item {} 
Python 2.7.14

\item {} 
sPyNNaker 8 (1!4.0.0)

\end{itemize}


\chapter{Sample Code}
\label{\detokenize{samplecode::doc}}\label{\detokenize{samplecode:sample-code}}
This section describes how to setup a simple Deep Spiking Convolutional Neural Network.


\section{Simple 1-Layer ConvNet}
\label{\detokenize{samplecode:simple-1-layer-convnet}}
Letâ€™s start with training a simple SCNN with one convolutional Layer. By creating firstly the model structure with the following python code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{SpikingModel}\PYG{p}{(}\PYG{n}{input\PYGZus{}tensor}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{run\PYGZus{}control}\PYG{o}{=}\PYG{n}{rc}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{ConvLayer}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{stride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Classifier}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

In order to build the network structure on SpiNNaker Hardware, you have to execute commands in the terminal:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode loaddata
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer \PYG{l+m}{1}
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer svm
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode testing
\end{sphinxVerbatim}


\section{Deeper ConvNet}
\label{\detokenize{samplecode:deeper-convnet}}
Theoritically, as many layers as appreciated can be build. Therefore convolutional layers are added to the model are added in sequential manner.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{SpikingModel}\PYG{p}{(}\PYG{n}{input\PYGZus{}tensor}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{run\PYGZus{}control}\PYG{o}{=}\PYG{n}{rc}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{ConvLayer}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{stride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{ConvLayer}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{stride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{ConvLayer}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,} \PYG{n}{stride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Classifier}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode loaddata
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer \PYG{l+m}{1}
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer \PYG{l+m}{2}
\PYG{g+go}{...}
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer n
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode training \PYGZhy{}\PYGZhy{}layer svm
\PYG{g+gp}{\PYGZdl{}}python main.py \PYGZhy{}\PYGZhy{}mode testing
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
The training of the Network is done layer by layer, hence the input spikes of the currently trained layer depend on the previous layer.
So a new simulation cycle is started the previously calculated layers are flattend to achieve parallel computation.
\end{sphinxadmonition}


\chapter{SpikingConvNet}
\label{\detokenize{modules:spikingconvnet}}\label{\detokenize{modules::doc}}

\section{SpikingConvNet package}
\label{\detokenize{SpikingConvNet:spikingconvnet-package}}\label{\detokenize{SpikingConvNet::doc}}

\subsection{Module contents}
\label{\detokenize{SpikingConvNet:module-SpikingConvNet}}\label{\detokenize{SpikingConvNet:module-contents}}\index{SpikingConvNet (module)}
Package for building Spiking Deep Convolutional Neural Networks on SpiNNaker
\begin{itemize}
\item {} 
Neuroscientific System Theory

\item {} 
Technical University Munich

\item {} 
Creator:    Sven Gronauer

\item {} 
Date:       February 2018

\end{itemize}

contains the necessary infrastructure and algorithms to build an arbitrarily deep
network described as a sequential model. The package SpikingConvNet is divided
into three modules, which will be proposed in the following:

\sphinxcode{Classes Module}
\begin{quote}

contains the object classes for creating models of the Spiking Neural Networks
and the necessary infrastructure for implementing such networks on SpiN-
Naker. A SCNN model is built by sequentially adding of convolutional layers
to the input layer and a classifier at last.
The Spinnaker Network class holds instances and methods to interact with
the SpiNNaker board. The structure is based on PyNNs procedure of creating
Spiking Networks. Neurons belonging to a particular layer of the neural net-
work and share common properties are packed into populations. Projections
establish connections between populations. The strength of a connection is
expressed by a numerical value, the synaptic weight that either increases the
membrane potential of the post-neuron (exhibitory) or lessens the membrane
potential (inhibitory).
The model is defined on the host-computer and then transferred to the SpiN-
Naker board, where the simulation is processed. When the simulation finishes,
data are retrieved back to the host-computer and post-processed.
\end{quote}

\sphinxcode{Algorithms Module}
\begin{quote}

provides functions for generating sparse connections between neural popula-
tions. The so-called projections between populations are employed by con-
nection lists, which are automatically built by considering the tensors of the
layers to be connected. Stride and kernel size specify the particular tensor of
the posterior layer by T\_n+1 = (T\_n - shape)/stride + 1.
In addition, the algorithms module supports the transformation of spiketrains.
Training deeper layers requires the network of the previous layers to be rebuilt
to obtain previous spiketrains. These spiketrains are transformed into plain
times to assign them to a spiking source array and train the actual layer with
the STDP update rule by windowing the input pattern over several time in-
stances. The training of the network is done layer by layer, hence the input
spikes of the currently trained layer depend on the previous layer. So a new
simulation cycle is started when a deeper layer is trained. Because the synap-
tic weights of previous layers are already determined, the previous layers are
rebuild as parallel entities and therefore profit in terms of computational speed.
\end{quote}

\sphinxcode{Parameters Module}
\begin{quote}

This file holds all important constants and parameters for controlling and
setting up the simulation.
\end{quote}

\sphinxcode{Utils Module}
\begin{quote}

Supporting functions to visualise and handle data. The training and test set
of the Spiking Neural Network is obtained by the MNIST dataset. Loading
a specified subset of MNIST digits defined in parameters.py and supplies the
network algorithms a shuffled set of data points.
Processed data is visualised with the plotting functions: convolutional kernels
can be plotted with heatmaps, spike times of each neuron along the time axis
and the membrane voltages over time.
\end{quote}


\subsection{Submodules}
\label{\detokenize{SpikingConvNet:submodules}}

\subsection{SpikingConvNet.algorithms module}
\label{\detokenize{SpikingConvNet:module-SpikingConvNet.algorithms}}\label{\detokenize{SpikingConvNet:spikingconvnet-algorithms-module}}\index{SpikingConvNet.algorithms (module)}
Algorithms are provided for
\begin{itemize}
\item {} 
Generating sparse connections between populations

\item {} 
Slice a layer into windows and split windows over time

\end{itemize}
\index{input\_flattend\_spikes() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.input_flattend_spikes}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{input\_flattend\_spikes}}{\emph{X\_train}, \emph{tensor\_input}, \emph{kernel\_shape}}{}
Create flattened SpikeSourceArray for input neurons
for instance in rebuilding network

For rebuilding the network structure the input neurons are not windowed
over time. Instead, the input layer is flattened and the entire image is
presented to the network in each simulation interval.
The corresponding spiketimes depend on pixel intensities and are
stochastically rate-coded.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{X\_train} (\sphinxstyleemphasis{np.array, shape = {[}n\_examples, image\_intensities.flatten(){]}}) \textendash{} dataset of MNIST input images as 2d-array

\item {} 
\sphinxstylestrong{tensor\_input} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of input layer

\item {} 
\sphinxstylestrong{kernel\_shape} (\sphinxstyleemphasis{tuple of int}) \textendash{} Kernel shape

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{spiketrains} \textendash{} Each datapoint contains precise spike times for each input neuron

\item[{Return type}] \leavevmode
np.array, shape = {[}n\_examples, spike\_times{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{input\_windowed\_spikes() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.input_windowed_spikes}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{input\_windowed\_spikes}}{\emph{X\_train}, \emph{tensor\_input}, \emph{kernel\_shape}, \emph{stride}}{}
Create windowed SpikeSourceArray for input neurons
for instance in training layers of the network

Input patterns are windowed over time, post-neurons are presented only
a subset of the input pattern. The corresponding spiketimes depend on
pixel intensities and are stochastically rate-coded.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{X\_train} (\sphinxstyleemphasis{np.array, shape = {[}n\_examples, image\_intensities.flatten(){]}})

\item[{Returns}] \leavevmode
\sphinxstylestrong{spiketrains} \textendash{} Each datapoint contains precise spike times for each input neuron

\item[{Return type}] \leavevmode
np.array, shape = {[}n\_examples*n\_windows, spike\_times{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{rebuild\_fixed\_connections() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.rebuild_fixed_connections}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{rebuild\_fixed\_connections}}{\emph{tensor\_first}, \emph{tensor\_second}, \emph{kernel\_shape}, \emph{stride}, \emph{weights\_tensor}}{}
Construct fixed connections between flattened layers

Take previously learned STDP weights and establish fixed weights.
The computation is handled now in parallel
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{tensor\_first} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of previous layer

\item {} 
\sphinxstylestrong{tensor\_second} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of posterior layer

\item {} 
\sphinxstylestrong{kernel\_shape} (\sphinxstyleemphasis{tuple of int}) \textendash{} Kernel shape

\item {} 
\sphinxstylestrong{stride} (\sphinxstyleemphasis{int}) \textendash{} Specified stride over convolved layer

\item {} 
\sphinxstylestrong{weights\_tensor} (\sphinxstyleemphasis{np.array, shape={[}n\_kernel, kernel\_height*kernel\_width{]}}) \textendash{} Previously trained STDP weights, now initialized as fixed weights

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{connection\_list} \textendash{} list for s.FromListConnector()

\item[{Return type}] \leavevmode
list of {[}position\_1, position\_2, weight , delay{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{rebuild\_inhibitory\_connections() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.rebuild_inhibitory_connections}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{rebuild\_inhibitory\_connections}}{\emph{tensor\_prev}, \emph{tensor\_layer}, \emph{inhib\_weight}}{}
Construct inhibitory connections within flattened layers
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{tensor\_prev} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of previous layer

\item {} 
\sphinxstylestrong{tensor\_layer} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of actual layer

\item {} 
\sphinxstylestrong{inhib\_weight} (\sphinxstyleemphasis{float32}) \textendash{} fixed weight for inhibitory connection

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{inhib\_connection\_list} \textendash{} list for s.FromListConnector()

\item[{Return type}] \leavevmode
list of {[}position\_1, position\_2, weight , delay{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{spikes\_for\_classifier() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.spikes_for_classifier}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{spikes\_for\_classifier}}{\emph{rc}, \emph{tensor}, \emph{spiketrains}}{}
Transform spiketrains to plain two-dimensional dataset

to reduce the power of Support Vector Machine, the quantity of spikes
within each simulation interval is counted for each neuron in the last
layer
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{tensor} (\sphinxstyleemphasis{tuple of int}) \textendash{} Tensor of last Convolutional layer in network

\item {} 
\sphinxstylestrong{spiketrains} (\sphinxstyleemphasis{SpikeTrain object}) \textendash{} Retrieved spikes from last layer on SpiNNaker board
SpikeTrains objects are extracted from Neo Block Segments

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{X} \textendash{} Each datapoint contains number of spikes for each post-neuron
within one sim interval

\item[{Return type}] \leavevmode
np.array, shape = {[}datapoints, n\_neurons\_last\_layer{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{windowed\_spikes() (in module SpikingConvNet.algorithms)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.algorithms.windowed_spikes}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.algorithms.}\sphinxbfcode{windowed\_spikes}}{\emph{spiketrains\_input}, \emph{tensor\_first}, \emph{tensor\_second}, \emph{kernel\_shape}, \emph{stride}}{}
Create windowed SpikeSourceArray
for instance in training deeper layers of the network

Input spiketrains are windowed over time, post-neurons are presented only
a subset of the input spiketrains. The corresponding output spiketimes
depend on calculated spikes (spiketrains\_input) of previous layer.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{spiketrains\_input} (\sphinxstyleemphasis{SpikeTrain object}) \textendash{} Spiketrains from previous layer

\item {} 
\sphinxstylestrong{tensor\_first} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of previous layer

\item {} 
\sphinxstylestrong{tensor\_second} (\sphinxstyleemphasis{tuple of int}) \textendash{} Dimensions of posterior layer

\item {} 
\sphinxstylestrong{kernel\_shape} (\sphinxstyleemphasis{tuple of int}) \textendash{} Kernel shape

\item {} 
\sphinxstylestrong{stride} (\sphinxstyleemphasis{int}) \textendash{} Specified stride over convolved layer

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{spiketrains} \textendash{} Each datapoint contains precise spike times for each neuron

\item[{Return type}] \leavevmode
np.array, shape = {[}n\_examples*windows, spike\_times{]}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{SpikingConvNet.classes module}
\label{\detokenize{SpikingConvNet:module-SpikingConvNet.classes}}\label{\detokenize{SpikingConvNet:spikingconvnet-classes-module}}\index{SpikingConvNet.classes (module)}
This module provides classes for creating objects of the neural network
model and the necessary infracture for building networks on SpiNNaker

Classes are namely:
\begin{itemize}
\item {} 
Layer

\item {} 
InputLayer(Layer)

\item {} 
ConvLayer(Layer)

\item {} 
Classifier(Layer)

\item {} 
SpikingModel

\item {} 
Spinnaker\_Network

\end{itemize}
\index{Classifier (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Classifier}}\pysigline{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{Classifier}}
Bases: {\hyperref[\detokenize{SpikingConvNet:SpikingConvNet.classes.Layer}]{\sphinxcrossref{\sphinxcode{SpikingConvNet.classes.Layer}}}}

Holds a linear Support Vector Machine for classifying
\index{predict() (SpikingConvNet.classes.Classifier method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Classifier.predict}}\pysiglinewithargsret{\sphinxbfcode{predict}}{\emph{X\_test}, \emph{y\_test}}{}
Determine classification accuracy of SVC with given Testset

\end{fulllineitems}

\index{train() (SpikingConvNet.classes.Classifier method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Classifier.train}}\pysiglinewithargsret{\sphinxbfcode{train}}{\emph{X\_train}, \emph{y\_train}}{}
Train parameters of SVM model with given Trainset

\end{fulllineitems}


\end{fulllineitems}

\index{ConvLayer (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.ConvLayer}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{ConvLayer}}{\emph{kernels}, \emph{shape}, \emph{stride}}{}
Bases: {\hyperref[\detokenize{SpikingConvNet:SpikingConvNet.classes.Layer}]{\sphinxcrossref{\sphinxcode{SpikingConvNet.classes.Layer}}}}

Specify a convolutional layer of the network

\end{fulllineitems}

\index{InputLayer (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.InputLayer}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{InputLayer}}{\emph{tensor}}{}
Bases: {\hyperref[\detokenize{SpikingConvNet:SpikingConvNet.classes.Layer}]{\sphinxcrossref{\sphinxcode{SpikingConvNet.classes.Layer}}}}

Specifies input layer of network

\end{fulllineitems}

\index{Layer (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Layer}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{Layer}}{\emph{rc}}{}
Bases: \sphinxcode{object}

Base class for network layers

\end{fulllineitems}

\index{SpikingModel (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.SpikingModel}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{SpikingModel}}{\emph{input\_tensor}, \emph{run\_control=None}}{}
Bases: \sphinxcode{object}

Describes structure of spiking neural network

A model consists of sequential topology of layers. The first layer is
provided as an input layer, followed by convolutional layers. The last
layer should be defined by a Classifier.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{input\_tensor} (\sphinxstyleemphasis{tuple of int}) \textendash{} Size of input patterns as 3d-Tensor

\item {} 
\sphinxstylestrong{run\_control} (\sphinxstyleemphasis{RunControl object}) \textendash{} Holds information of program flow

\end{itemize}

\end{description}\end{quote}
\index{add() (SpikingConvNet.classes.SpikingModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.SpikingModel.add}}\pysiglinewithargsret{\sphinxbfcode{add}}{\emph{layer}}{}
Adds sequentially a layer to the network model

\end{fulllineitems}

\index{print\_structure() (SpikingConvNet.classes.SpikingModel method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.SpikingModel.print_structure}}\pysiglinewithargsret{\sphinxbfcode{print\_structure}}{}{}
Print struture of model in console

\end{fulllineitems}


\end{fulllineitems}

\index{Spinnaker\_Network (class in SpikingConvNet.classes)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Spinnaker_Network}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.classes.}\sphinxbfcode{Spinnaker\_Network}}{\emph{runcontrol}, \emph{model}, \emph{deepspikes=None}}{}
Bases: \sphinxcode{object}

Class for implementing neural network model on SpiNNaker

The following steps are processed through calling the class constructor
(based on PyNN basic setup structure)
\begin{enumerate}
\item {} 
Initialize with constructor

\item {} 
Load datasets (Train and Testset) from local files

\item {} 
Load previously calculated weights for layers (if given in /model)

\item {} 
Create populations

\item {} 
Build STDP-model

\item {} 
Build projections between populations

\item {} 
Setup recordings

\end{enumerate}

The following methods must be called from external fuction(s):
\begin{itemize}
\item {} 
update\_kernel\_weights() - Determine current weights in STDP trained layer

\item {} 
retrieve\_data() - Receive recorded data from SpiNNaker

\item {} 
print\_parameters() - Display information of neural network

\end{itemize}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{runcotrol} (\sphinxstyleemphasis{RunControl object}) \textendash{} Structure that contains basic information for program flow such as
passed args from terminal command, backup commands, building options
for SpiNNaker network

\item {} 
\sphinxstylestrong{model} (\sphinxstyleemphasis{SpikingModel object}) \textendash{} predefined model of spiking neural network

\item {} 
\sphinxstylestrong{deepspikes} (\sphinxstyleemphasis{Spiketrain object}) \textendash{} training a deeper layer requires preprocessed spikes from previous
layer, hence training of Spiking Neural Network is done layer by
layer

\end{itemize}

\end{description}\end{quote}
\index{print\_parameters() (SpikingConvNet.classes.Spinnaker\_Network method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Spinnaker_Network.print_parameters}}\pysiglinewithargsret{\sphinxbfcode{print\_parameters}}{}{}
Print parameters of model and simulation to console

\end{fulllineitems}

\index{retrieve\_data() (SpikingConvNet.classes.Spinnaker\_Network method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Spinnaker_Network.retrieve_data}}\pysiglinewithargsret{\sphinxbfcode{retrieve\_data}}{}{}
Transmit observed data of spikes and voltages from SpiNNaker Board
to host computer
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\sphinxstylestrong{spiketrains} (\sphinxstyleemphasis{SpikeTrain object}) \textendash{} Spiketrains from last layer in neural network

\item {} 
\sphinxstylestrong{list} (\sphinxstyleemphasis{{[}spikes\_in, spikes\_1, v\_1{]}}) \textendash{}
\begin{itemize}
\item {} 
spikes\_in: spiketimes input layer

\item {} 
spikes\_1: spikes post-neurons

\item {} 
v\_1: membrane potentials of post-neurons

\end{itemize}

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{update\_kernel\_weights() (SpikingConvNet.classes.Spinnaker\_Network method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.classes.Spinnaker_Network.update_kernel_weights}}\pysiglinewithargsret{\sphinxbfcode{update\_kernel\_weights}}{}{}
Update the internal variables of weights

Receive actual weight values of trained STDP layer from SpiNNaker
board and store to self.w\_layer variable
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode


\item[{Return type}] \leavevmode
weights, np.array, shape = {[}n\_kernels, flattend\_weights{]}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\subsection{SpikingConvNet.parameters module}
\label{\detokenize{SpikingConvNet:spikingconvnet-parameters-module}}\label{\detokenize{SpikingConvNet:module-SpikingConvNet.parameters}}\index{SpikingConvNet.parameters (module)}
This file holds all important constans and parameters for controlling the
simulation

\begin{sphinxadmonition}{note}{Note:}
Any adjustments applied to this file have an impact to all other files in
the project!
\end{sphinxadmonition}


\subsection{SpikingConvNet.utils module}
\label{\detokenize{SpikingConvNet:spikingconvnet-utils-module}}\label{\detokenize{SpikingConvNet:module-SpikingConvNet.utils}}\index{SpikingConvNet.utils (module)}
Utilities for controling program flow, data handling and data plotting
\index{RunControl (class in SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.RunControl}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{RunControl}}{\emph{args}, \emph{trainlayer=0}, \emph{trainsvm=False}, \emph{rebuild=False}}{}
Bases: \sphinxcode{object}

Object for controlling program flow, contains args from console and sets
up the logging utility
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{args} (\sphinxstyleemphasis{ArgumentParser object}) \textendash{} Passed arguments from terminal command

\item {} 
\sphinxstylestrong{trainlayer} (\sphinxstyleemphasis{int, optional}) \textendash{} If not zero, specifies which layer of network to train

\item {} 
\sphinxstylestrong{trainsvm} (\sphinxstyleemphasis{bool, optional}) \textendash{} If given, classifier is trained

\item {} 
\sphinxstylestrong{rebuild} (\sphinxstyleemphasis{bool, optional}) \textendash{} Controls the behaviour of the follow up build of neural network
(as a variable of programs state machine)
\begin{itemize}
\item {} 
\sphinxcode{rebuild==True} in order to train layer n, the spikes of layer n-1 must be determined

\item {} 
\sphinxcode{rebuild==False} a layer or the Classifier is trained

\end{itemize}

\end{itemize}

\end{description}\end{quote}
\index{setup\_logger() (SpikingConvNet.utils.RunControl method)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.RunControl.setup_logger}}\pysiglinewithargsret{\sphinxbfcode{setup\_logger}}{}{}
Setup logger for tracking infos and errors

\end{fulllineitems}


\end{fulllineitems}

\index{convert\_rate\_code() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.convert_rate_code}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{convert\_rate\_code}}{\emph{intensity}, \emph{total\_intensity=None}}{}
Rate code spikes - Assign pixel intensity to stochastic spike times

calculate spike times dependend on pixel intensity of pre-neuron
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{intensity} (\sphinxstyleemphasis{int, {[}0,255{]}}) \textendash{} Pixel intensity

\item {} 
\sphinxstylestrong{total\_intensity} (\sphinxstyleemphasis{int}) \textendash{} Sum of intensities of input pattern for normalization

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{spiketimes} \textendash{} Corresponding spike times for pixel intensity

\item[{Return type}] \leavevmode
list, of int

\end{description}\end{quote}

\end{fulllineitems}

\index{convert\_time\_code() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.convert_time_code}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{convert\_time\_code}}{\emph{intensity}}{}
Time code spikes - Assign pixel intensity to deterministic time interval
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{intensity} (\sphinxstyleemphasis{int, {[}0,255{]}}) \textendash{} Pixel intensity

\item[{Returns}] \leavevmode
\sphinxstylestrong{spiketime} \textendash{} Corresponding spike time for pixel intensity

\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{dog\_filter() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.dog_filter}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{dog\_filter}}{\emph{image}}{}
Apply Difference of Gaussian Filter to image
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstylestrong{image} (\sphinxstyleemphasis{np.array, shape={[}height, width{]}}) \textendash{} Image to be transformed

\item[{Returns}] \leavevmode
\sphinxstylestrong{norm\_dog} \textendash{} Transformed image

\item[{Return type}] \leavevmode
np.array, shape={[}height, width{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{load\_MNIST\_digits\_shuffled() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.load_MNIST_digits_shuffled}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{load\_MNIST\_digits\_shuffled}}{\emph{rc}, \emph{mode}}{}
Load MNIST dataset

load defined number of examples (see parameters.py)
loaded subset of digits is defined in SUBSET\_DIGITS
shuffle data and return as 2d-arrays
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{rc} (\sphinxstyleemphasis{RunControl object}) \textendash{} contains information of backup behaviour

\item {} 
\sphinxstylestrong{mode} (\sphinxstyleemphasis{str}) \textendash{}
\begin{itemize}
\item {} 
\sphinxcode{train\_examples} Examples for Trainset are loaded

\item {} 
\sphinxcode{test\_examples} Examples for Testset are loaded

\end{itemize}

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{f} \textendash{} Object of figure

\item[{Return type}] \leavevmode
figure object

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_confusion\_matrix() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_confusion_matrix}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_confusion\_matrix}}{\emph{rc}, \emph{cm}, \emph{normalize=True}, \emph{title='Confusion\_matrix'}, \emph{cmap=\textless{}matplotlib.colors.LinearSegmentedColormap object\textgreater{}}}{}
This function prints and plots a confusion matrix.
Normalization can be applied by setting \sphinxcode{normalize=True}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{rc} (\sphinxstyleemphasis{RunControl object}) \textendash{} contains information of backup behaviour

\item {} 
\sphinxstylestrong{cm} (\sphinxstyleemphasis{np.array,}) \textendash{} Contains values of the confusion matrix

\item {} 
\sphinxstylestrong{normalize} (\sphinxstyleemphasis{bool}) \textendash{} If \sphinxcode{True} Matrix is normalized

\item {} 
\sphinxstylestrong{title} (\sphinxstyleemphasis{str}) \textendash{} defines title of figure and name of saved figure on disk

\item {} 
\sphinxstylestrong{cmap} (\sphinxstyleemphasis{cm object}) \textendash{} Color scheme of the plot

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{f} \textendash{} Object of figure

\item[{Return type}] \leavevmode
figure object

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_heatpmap() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_heatpmap}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_heatpmap}}{\emph{rc}, \emph{list\_of\_elements}, \emph{title='Default Title'}, \emph{delta=False}}{}
Plot a matrix of heatmaps
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{rc} (\sphinxstyleemphasis{RunControl object}) \textendash{} contains information of backup behaviour

\item {} 
\sphinxstylestrong{list\_of\_elements} (\sphinxstyleemphasis{list}) \textendash{} List of np.arrays with shape={[}n,n{]}

\item {} 
\sphinxstylestrong{title} (\sphinxstyleemphasis{str}) \textendash{} defines title of figure and name of saved figure on disk

\item {} 
\sphinxstylestrong{delta} (\sphinxstyleemphasis{bool}) \textendash{} if defined, use dirrential color scheme for heatmap plot

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{f} \textendash{} Object of heatmap

\item[{Return type}] \leavevmode
figure object

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_membrane\_voltages() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_membrane_voltages}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_membrane\_voltages}}{\emph{rc}, \emph{v\_data}, \emph{simtime}, \emph{title='Membrane potentials'}}{}
Plot the membrane potential
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{rc} (\sphinxstyleemphasis{RunControl object}) \textendash{} contains information of backup behaviour

\item {} 
\sphinxstylestrong{v\_data} (\sphinxstyleemphasis{Voltage Object}) \textendash{} Contains values of the membrane potentials

\item {} 
\sphinxstylestrong{simtime} (\sphinxstyleemphasis{int}) \textendash{} Maximum simulation time on the x-axis

\item {} 
\sphinxstylestrong{title} (\sphinxstyleemphasis{str}) \textendash{} defines title of figure and name of saved figure on disk

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{f} \textendash{} Object of figure

\item[{Return type}] \leavevmode
figure object

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_spike\_activity() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_spike_activity}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_spike\_activity}}{\emph{rc}, \emph{spiketrains}, \emph{tensor}, \emph{title='plot\_spike\_activity'}}{}
Plot the activity of each neurons in the given layer in the first
simulation interval

The quantity of spikes for each neuron in the layer (given with tensor
and its spiketrains) are determined for the first simulation interval
and then plotted as heatmap
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{rc} (\sphinxstyleemphasis{RunControl object}) \textendash{} contains information of backup behaviour

\item {} 
\sphinxstylestrong{spiketrains} (\sphinxstyleemphasis{SpikeTrain Object}) \textendash{} List of np.arrays with shape={[}n,n{]}

\item {} 
\sphinxstylestrong{tensor} (\sphinxstyleemphasis{tuple of int}) \textendash{} Tensor of Layer

\item {} 
\sphinxstylestrong{title} (\sphinxstyleemphasis{str}) \textendash{} defines title of figure and name of saved figure on disk

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{f} \textendash{} Object of figure

\item[{Return type}] \leavevmode
figure object

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_spikes() (in module SpikingConvNet.utils)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{SpikingConvNet:SpikingConvNet.utils.plot_spikes}}\pysiglinewithargsret{\sphinxcode{SpikingConvNet.utils.}\sphinxbfcode{plot\_spikes}}{\emph{rc}, \emph{pre}, \emph{post=None}, \emph{title='Spikes Plot'}, \emph{path=None}}{}
Plot spikes of given layers
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstylestrong{rc} (\sphinxstyleemphasis{RunControl object}) \textendash{} contains information of backup behaviour

\item {} 
\sphinxstylestrong{pre} (\sphinxstyleemphasis{SpikeTrain object}) \textendash{} Spiketrains of first layer to plot

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxstylestrong{norm\_dog} \textendash{} Transformed image

\item[{Return type}] \leavevmode
np.array, shape={[}height, width{]}

\end{description}\end{quote}

\end{fulllineitems}



\chapter{Miscellaneous}
\label{\detokenize{misc::doc}}\label{\detokenize{misc:miscellaneous}}

\section{Build documentation}
\label{\detokenize{misc:build-documentation}}
How to build the documentation:
\begin{enumerate}
\item {} 
Change directory:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} cd docs/
\end{sphinxVerbatim}

\item {} 
If major changes have been submitted to the code, then render:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} sphinx\PYGZhy{}apidoc \PYGZhy{}f \PYGZhy{}o source/ ../SpikingConvNet/
\end{sphinxVerbatim}

\item {} 
Execute to create HTML Documentation in \sphinxcode{/build/html} directory:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} make html
\end{sphinxVerbatim}

\item {} 
Excute to create PDF of Documentation in \sphinxcode{/build/latex} directory:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} make latexpdf
\end{sphinxVerbatim}

\end{enumerate}


\section{Obtain MNIST-Dataset}
\label{\detokenize{misc:obtain-mnist-dataset}}
thanks to \sphinxstyleemphasis{https://pypi.python.org/pypi/python-mnist}

Get the package from PyPi:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} pip install python\PYGZhy{}mnist
\end{sphinxVerbatim}

or install with \sphinxcode{setup.py}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} cd python\PYGZhy{}mnist/
\PYGZdl{} python setup.py install
\end{sphinxVerbatim}

Code sample:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{mnist} \PYG{k}{import} \PYG{n}{MNIST}
\PYG{n}{mndata} \PYG{o}{=} \PYG{n}{MNIST}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{./dir\PYGZus{}with\PYGZus{}mnist\PYGZus{}data\PYGZus{}files}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{images}\PYG{p}{,} \PYG{n}{labels} \PYG{o}{=} \PYG{n}{mndata}\PYG{o}{.}\PYG{n}{load\PYGZus{}training}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Clean up directory}
\label{\detokenize{misc:clean-up-directory}}
Delete all .pyc files with command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdl{} bash cleanup.sh
\end{sphinxVerbatim}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{s}
\item {\sphinxstyleindexentry{SpikingConvNet}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet}}
\item {\sphinxstyleindexentry{SpikingConvNet.algorithms}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet.algorithms}}
\item {\sphinxstyleindexentry{SpikingConvNet.classes}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet.classes}}
\item {\sphinxstyleindexentry{SpikingConvNet.parameters}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet.parameters}}
\item {\sphinxstyleindexentry{SpikingConvNet.utils}}\sphinxstyleindexpageref{SpikingConvNet:\detokenize{module-SpikingConvNet.utils}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}